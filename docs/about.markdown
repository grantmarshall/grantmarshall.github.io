---
layout: page
title: About
permalink: /about/
---

My name is Grant Marshall and I've worked professionally in Software for about
ten years. My last major job was working for Google as a Full Stack Engineer
under the Ads organization. My primary project was working on implementing new
features for and maintaining the Overview page in
[Adwords](https://business.google.com/us/google-ads/), which served as the home
page and landing point for anyone using the Adwords web client. I also
designed and implemented most of the Adwords Insights system, which generated
deeper statistical insights into an Adwords account and made them available for
visualization on the Overview among other places in the web and mobile clients.

Before Google, I worked at ASU in the [Data Mining and Machine Learning](https://dmml.asu.edu/)
for the entire duration of my Undergraduate studies. There I helped make tools
for scraping and visualizing data from a variety of social media platforms, most
notably Twitter. In addition, for six months I worked at [TGen](https://www.tgen.org/)
as part of the [Helios Scholars](https://www.tgen.org/education/helios-scholars-at-tgen/)
program, using my understanding of computing systems and scripting to build out
pipelines that processed whole genome sequence data to help identify potential
genetic variations that might lead to higher incidences of colorectal and breast
cancer.

Outside of pure technical implementation work, I also spent a little over a year
working as a student editor for [KDNuggets](https://www.kdnuggets.com/), a site
ran by Dr. Gregory Piatetsky that posts on subjects of interest to the Knowledge
Discovery community. There, I wrote original articles and demos, in addition to
editing the articles of other community members that wanted to share their
knowledge or promote their tools.

In 2021 after working remotely for a few years, I chose to leave Google to spend
some time with family and friends I was able to reconnect with since moving back
to my hometown of Phoenix. For the last few years my technical work consisted
mainly of dabling with deep-learning models for a variety of tasks. The primary task
I was interested in was live audio translation since I had been in the process
of learning Japanese myself and was interested in how well these new models
could handle the task. The primary model I work with is [Whisper](https://github.com/openai/whisper),
and the first series of posts I'm going to author are on how to adapt the model to a streaming
audio setting. I'm making this site initially to share what I've found from using
these models and to help other people potentially understand how they can apply
them to actual production-ready code.
